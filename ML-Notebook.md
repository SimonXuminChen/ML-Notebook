# ML Notebook

## 1. Feature Engineering 特征工程

### 1.1 特征选择

#### 1.1.1如何选择特征？

基于业务理解，尽可能找出对因变量有影响的所有自变量。



#### 1.1.2如何评估特征的可用性？

从三个方面去评估：特征数据的获取难度、覆盖率、准确率。



### 1.2 特征处理

未经过处理的特征可能会出现以下情况：

- 不同量级
- 离散型特征
- 存在缺失值
- 信息利用率低

#### 1.2.1数据清洗

**To-Do:待补充**



#### 1.2.2归一化

#### 1.2.4离散型特征的处理方式

许多模型和算法都需要数值特征作为输入，因此需要将离散型的特征转换为数值特征。

离散型特征转换数值特征的方法：

- 序列编码
- one-hot编码
- 二进制编码



##### 序列编码

序列特征通常用来处理具有大小关系的特征。

如果特征中是可以被等级划分的，则可以划分成高中低等级，通过使用序列编码，将低等级用1表示，中等级用2表示，高等级用3表示。

##### one-hot编码

根据特征的数量，将每个特征编码成1*N维的向量，只有代表这个特征的维度表示为1，其他维度表示为0。

会具有**维度爆炸**的问题。

##### 二进制编码

将特征通过过序列标注，然后以二进制的形式，将特征序列号转换为二进制，这样可以减少空间。



#### 1.2.5缺失值的处理

1. 通过平均值、中值、众数、随机值等替代。效果一般，因为这相当于人为添加了噪声。
2. 通过欧式距离或者Pearson相似度，来确定与缺失数据样本最近的K个样本， 将这K个样本的相关特征加权平均来估计该样本的缺失值。
3. 将变量映射到高维空间
   - 离散型变量：通过one-hot编码，映射成三个变量：男，女，缺失三个值向量
   - 连续性变量：进行分箱操作，采用一定的数据平滑方式（平均值/中值/箱边界）进行离散化，然后增加是否缺失这种维度。
4. 通过已有数据作线性回归，预测缺失值。

#### 1.2.6离群值outliers的处理

因为过大或过小的数据可能会影响到分析结果，尤其是在做回归的时候，我们需要对那些离群值进行处理。

> 离群值和极值是不一样的，极值不一定会影响分析结果。

检测方法：

1. 基于标准差（Standard2Deviations, SD）法
   a为一组数的平均数，b为这组数的标准差，则超出[a-2b, a+2b]范围的值即被认为离群值。

   

   这种方法不是特别的靠谱，因为离群值的出现可能反过来很大程度影响平均数和标准差，所以平均数或者标准差受离群值的制约而使得这个检测方法不靠谱。

2. 基于绝对离差中位数（Median Absolute Deviation, MAD）的中心距离计算法
  （1）计算所有观察点的中位数median(X);
  （2）计算每个观察点与中位数的绝对偏差值abs(X-median(X));
  （3）计算（2）中的绝对偏差值的中位数，即MAD = median(abs(X - median(X)));
  （4）之后选定n值，从而确定合理的范围

  $$X_i^{'} = \begin{cases}  
  X_{median}+nMAD & X_i>X_{median}+nMAD \\
  X_{median}-nMAD & X_i<X_{median}-nMAD \\
  X_i & X_{median}-nMAD<X_i<X_{median}+nMAD
  \end{cases}$$

  这是一种稳健对抗离群数据的距离值方法，采用计算各观测值与平均值的距离总和的方法。放大了离群值的影响，相比基于SD的中位数距离法，它可以更清晰地从正常观察点中检测出离群值来。

3. 百分位法

   计算的逻辑是将因子值进行升序的排序，对排位百分位高于97.5%或排位百分位低于2.5%的因子值，进行类似于前两种方法的处理。

4. Box plot

另外，在RMSE中，outliers会给模型评估造成很大的影响，所以要在预处理阶段过滤掉outliers，或者进一步提高模型的预测能力，也可以根管一个合适的评估指标，如MAPE(Mean Absolute Percent Error平均绝对百分比误差)，计算公式为$$MAPE = \sum_{i=1}^n |\frac {y_i-y_i^{hat}}{y_i}|*\frac {100}{n}$$

MAPE将每个样本的误差进行了归一化，降低了个别outliers带来的绝对误差的影响。



#### 1.2.7特征组合

有时候为了提高复杂关系的拟合能力，在特征工程中经常会把一阶离散特征两两组合，构成高阶组合特征。

##### 组合方法

- A*A
- A*B
- A\*B\*C*D

##### 处理高维特征

有时候，特征的数量过大（可以达到千万量级），这时候几乎是无法学习到这种规模的参数，因此可以采用矩阵分解的方法将特征用低维向量的方法表示。

##### 如何选择组合特征

可以采用GBDT（梯度提升决策树）的方法，每次都在之前构建的决策树的残差上构建下一棵决策树。



#### 1.2.8特征选择

数据预处理结束之后，我们要选择有意义的特征去输入算法和模型进行训练，通常从以下两个方面来考虑：

- 是否发散
- 与目标的相关性



特征的选择方法可以分为Filter法（过滤法）、Wrapper法（包装法）、Embedded法（嵌入法）

##### Filter法-过滤法

按照发散性或者相关性，对各个特征进行评分，设定阈值或者选择阈值的个数，选择特征。

- 方差选择法：先计算各个特征的方差，选择方差大于阈值的特征。

- 相关系数法：先计算各个特征对目标值的相关系数P值。

- 卡方检验(Chi-square test)：检验定性自变量对定性因变量的相关性。$$x^2 = \sum \frac {(Observed - Expect)^2}{Expect}$$

  结合自由度、置信度查表分析。

  _reference-《结合日常生活的例子，了解什么是卡方检验》:https://www.jianshu.com/p/807b2c2bfd9b_

  

##### Wrapper法-包装法

根据目标函数（通常是预测效果评分），每次选择若干特征，或者排除若干特征。

- 递归特征消除法：使用一个及模型来进行多轮训练，每轮训练后，消除若干权值系数的特征

##### Embedded法-嵌入法

先试用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。类似于Filter方法，但是通过训练来确定特征的优劣。

- 基于惩罚项的特征选择法：使用带有惩罚项的基模型，除了筛选出特征外，同时也进行了降维
- 基于树模型的特征选择法(GBDT)

#### 1.2.9降维处理

当特征选择完成后，如果特征矩阵过大，会导致计算量大、训练时间长，所以为了有效、快速的训练模型，降低特征矩阵维度是一个有效的手段。



常见的降维方法除了基于L1惩罚项的模型外，还有以下两种方法：

- PCA（主成分分析）
- LDA（线性判别分析）

> 线性判别分析本身也是一个分类模型

PCA和LDA有很多共同点，本质都是要将原始的样本映射到维度更低的样本空间。但是两者的映射目标不一样，PCA是为了让银蛇后的样本具有最大发散性；而LDA是为了让映射后的样本有最好的分类性能。

所以，PCA是一种无监督的降维方法，而LDA是一种有监督的降维方法。



## 2. 模型评估

在机器学习领域，模型的评估也至关重要，只有选择与问题相匹配的评估方法，才能快速发现模型选择或训练过程中出现的问题，迭代地对模型进行优化。如果不能合理的运用评估指标，不仅不能发现模型的问题，还会得出错误的结论。



模型评估主要分为两个阶段：离线评估和在线评估。

离线评估：模型未部署到生产环境之前。首先需要训练一个模型，然后对训练好的模型进行离线评估来了解下模型的性能情况。



线上评估：模型部署到生产环境之后。采用训练好的模型。





>  不同的模型有不同的评估指标



先说一下几个通常使用的标准：

**准确率Accuracy：**指分类正确的样本站样本个数的比例，是最简单也是最直观的评价指标。公式如下：

$$Accuracy = \frac {n_{correct}} {n_{total}} $$

但是准确率有一个明显的缺陷，当数据样本不均衡的时候，占比重较大的类别会成为影响准确率的最主要因素。所以可以通过**平均准确率**（每个类别下的样本准确率的算术平均）作为模型评估的指标。



**精准率Precision：**指分类正确的正样本个数占分类器判定为正样本的样本个数比例。

$$Precision = \frac {n_{predicted true & actual true} }{n_{predicted true}}$$

**召回率Recall：**指分类正确的正样本个数占真正正样本个数的比例。

$$Recall = \frac {n_{predicted true}} {n_{actual true}}$$



**F1-score：**：是精准率和召回率的调和平均值

$$F1 = \frac {2\*precision\*recall}{precision+recall}$$

Precision和Recall是及矛盾又统一的两个指标，为了提高Precision值，分类器需要尽量在“更有把握”时，才把样本预测为正样本，但是此时会往往因为过于保守而漏掉很多“没有把握”的正样本，导致Recall降低。



> 在排序问题中，通常没有一个确定的阈值把得到的结果直接判定为正样本或负样本，而是采用TopN返回结果的Precision和Recall来衡量排序模型的性能，即认为模型返回的TopN结果就是模型判定的正样本，然后计算前N个位置上的准确率Precision@N和召回率Recall@N.



为了综合一个模型的好坏，不仅要看Precision@N和Recall@N，而且最好绘制出模型的**P-R曲线（Precision-Recall Curve）**

### 2.1 Precision-Recall Curve

P-R曲线的很轴是召回率，纵轴是精确率。P-R曲线上的一个点代表在某一阈值下，模型将大于该阈值的结果判定为正样本，小于的判定为负样本，此时的返回结果对应的召回率和精确率。

整条P-R曲线是通过将阈值从高到低移动而生成的，原点附近代表当阈值最大时，模型的精确率和召回率

**To-Do:补充图片**



最重要的是，不能只通过某个点对应的精确率和召回率去全面衡量模型的性能，这是不准确的，只有通过P-R曲线的整体表现，才能对模型进行更为全面的评估。



**MAPE**

之前提到过。



##### Confusion Matrix



### 2.2 ROC & AUC

#### 2.2.1 ROC(Receiver Operation Characteristic Curve 受试者工作特征曲线)

TAT这名字真难记。

ROC的横轴为假阳性率（False Positive Rate, FPR）,纵轴为真阳性率（True Positive Rate,TPR）。

$$ FPR = \frac {FP}{N}$$

$$TPR = \frac{TP}{P}$$

$$注意：N不是样本总个数，而是真实的负样本的数目；P是真实的正样本数目$$

ROC曲线一般都处于 $y=x$这条直线的上访，如果不是，只需要通过翻转模型预测的概率成1-p即可得到一个更好的分类器。

#### 2.2.2 如何绘制ROC

ROC曲线是通过不断移动分类器的“截断点”来生成曲线上的一组关键点的。

绘制方法一：

1. 首先根据样本标签统计出正负样本的数量，假设正样本数量为P，负样本数量为N；
2. 接下来把横轴的刻度间隔设置为1/N，纵轴的刻度间隔设置为1/P；
3. 再根据模型输出的预测概率对样本进行排序（从高到低）
4. 依次遍历样本，同事从零开始绘制ROC曲线，没遇到一个正样本就沿纵轴方向绘制一个刻度间隔的曲线，没遇到负样本就沿横轴方向绘制一个刻度间隔的曲线，知道遍历完所有的样本；
5. 曲线最终停留在 (1,1) 这个点，整个ROC曲线绘制完成。



绘制方法二：

1. 将样本按照预测概率从高到低排序，在输出最终的正负样本之前，设定阈值，大于阈值的为正例，小于阈值的为负例
2. 通过动态地调整截断点（阈值），从正无穷开始，逐渐减小阈值到0，每一个截断点都会对应一个FPR和TPR
3. 在ROC图上绘制出每个截断点对应的位置
4. 连接所有点得到ROC曲线



#### 2.2.3 AUC（Area Under the Curve）

顾名思义，就是ROC曲线下的面积，AUC可以量化地反应基于ROC曲线衡量出的模型性能。

**AUC计算：**沿着ROC横轴方向做积分。取值一般在0.5~1之间。

> AUC的值越大，说明分类器月可能吧真正的正样本排在前面，分类性能越好。



#### 2.2.4 ROC和P-R Curve的区别

当正负样本的分布发生变化的时候，P-R Curve会发生剧烈的变化，而ROC的形状基本保持不变，即ROC曲线能够尽量降低不同测试集带来的干扰，更加客观地衡量模型本身的性能。

但是直观上，P-R Curve更能反映模型在特定数据集的性能。



### 2.3 距离计算

在模型的训练过程中，也需要不断评估样本之间的相似性（距离）。

而距离与相似度的关系为:$Distance = 1- Similarity$

机器学习问题中，通常将特征表示为向量的形式，所以在分析两个特征向量之间的相似性时，常用余弦相似度表示。

余弦相似度的取值范围[-1,1]，相同的两个向量之间的相似度为1。余弦距离的取值范围是[0,2]，相同的两个向量的余弦距离为0。



另外的距离和相似度方法有

距离：

- 欧式距离
- 余弦距离



相似度：

- Pearson coefficient
- 余弦相似度



#### 2.3.1 距离定义

**定义：**在一个集合中，如果每一对元素均可唯一确定一个实数，使得三条距离公理（正定性，对称性，三角不等式）成立，则该实数可称为这对元素之间的距离。

正定性：大于0

对称性：dist(A,B)=dist(B,A)

三角不等式：a+b>c



#### 2.3.2 余弦相似度

$ cos(A,B)= \frac {A·B}{||A||_2||B||_2}$

  取两个向量夹角的余弦，关注的是向量之间的角度关系，并不关心值的大小。

**余弦相似度和欧氏距离的关系**

在维度高的时候，余弦相似度依然保持“相同为1，正交时为0，相反时为-1”，而欧式距离则受严重的影响，范围不固定。

> 欧氏距离体现的是数值上的绝对差异，而余弦距离体现方向上的相对差异。

如果向量的模长是讲过归一化处理，欧氏距离与余弦距离有着单点关系：$$||A-B||_2 = \sqrt {2(1-cos(A,B))}$$





注意：根据距离的定义，余弦距离并不是一个严格定义的距离，因为并不满足三角不等式这一点，这一点可以通过(0,1),(1,0),(1,1)这三个向量来距离证明，或者通过余弦距离和欧式距离的关系来证明。

此外，同样不属于严格定义的距离还有KL散度（KL距离）。

- KL散度常用于计算两个分部之间的差异。



##### TO-DO:补充常用距离



### 2.4 A/B Test

在机器学习中，A/B Test是验证模型最终效果的主要手段，是为同一个目标制定的两个方案，在同一时间维度，分别让组成成分相同或相似的用户群组随机的使用一个方案，收集各群主的用户体验数据和业务数据，最后根据显著性分析评估出最好版本正式采用。

测试目的：页面（版本）的某一特定更新对目的指标的影响效果。

简单来讲，A/B Test是用来对产品的两个版本进行比较，将用户随机分成两组，这两组数据可以来自同一分布。

一组叫做对照组，用原始版本，另一组叫做实验组，使用新版。

**同时做线上测试，然后采集指标，分析结果。**



#### 2.4.1 线上A/B Test的原因

1. 离线评估无法完全消除模型过拟合的影响。
2. 离线评估无法还原线上的工程环境，考虑不到实际的情况，如数据分布，数据丢失，标签数据缺失等。
3. 某些业务指标在离线评估中无法计算。离线评估一般是针对模型本身进行评估，而与模型相关的其他指标，特别是商业指标往往无法直接获得。

#### 2.4.2 如何进行线上A/B Test

主要手段是对用户进行分桶，根据对照组和实验组分用户，分桶的过程中需要注意样本的独立性和采样方式的无偏性，确保同一个用户只能分到一个桶中，在分桶过程中，user_id需要是随机数，这样才能保证桶中的样本是无偏的。



### 2.5 模型评估方法

机器学习中，通常将样本分为训练集和测试集，训练集用于训练模型，使模型学习到参数，测试集用于评估模型。

#### 2.5.1主要的验证方法

1. Holdout 验证

   最简单的验证方法，将原数据集直接分成训练集和验证集，一般是训练集70%，验证集30%。但是该验证方法与分组有关，导致结果会出现随机性。

2. 交叉验证 Cross-Validation

   对Holdout验证法的改进。

   k-fold：交叉验证的一种，首先将样本分为k个相等大小的样本子集，依次遍历这些子集。遍历时，把当前子集作为验证集，其余子集作为训练集，进行模型的训练和评估。最后把k次评估指标的**平均值**作为最终的评估指标。

   留p验证：每次都留下p个样本作为验证集（从n个元素中选择p个元素,总共$C_n^p$种可能。开销大。

   leave-one-out: 留一法，留p验证的特例45，每次留下一个样本作为验证集，其余样本作为测试集。同样是遍历所有的样本，并取平均值作为最后评估指标。**样本数量大的时候，留一法的时间开销大。**

   

3. 自助法

   总共有n个样本，每次都从样本中有放回的随机抽取一个，直到训练集的数量达到n个为止，其中有可能抽取到相同的样本，将剩下未抽到的样本作为验证集。

   自助法是在样本数量不足的情况下提出的，因为样本数量少，如果采用Holdout或cross-validation的话， 会导致样本数量更加稀少。

   当n趋向于无穷大的时候，大概有0.368左右的数据未被选择过。



### 2.6 超参数调优

调参侠来了！

除了根据经验设定的所谓的合理值之外，一般很难找到合理的方法去寻找超参数的最优取值。

优化目标：

1. 目标函数（损失函数），即算法需要最大化或最小化的目标
2. 搜索范围，一般通过上限和下限决定
3. 其他参数，比如搜索步长



为了进行超参数调优，一般采用以下的方法：

- 网格搜索
- 随机搜索
- 贝叶斯优化



##### 网格搜索

通过查找搜索范围内的所有的点来确定最优值。

如果采用较大的搜索范围和较小的步长，那么很大概率找到全局最优值，但是这样的计算开销十分大，尤其是需要调参的超参数比较多的时候。

所以实际上，先采用**较广的搜索范围和较大的步长**去寻找到最有可能存在最优解的位置，然后逐渐**缩小搜索范围和步长**去寻找更精确的最优值。这样可以降低计算量和时间，但是由于目标函数一般是**非凸**的，所以很可能错过全局最优解。



##### 随机搜索

与网格搜索相似，不过不像网格搜索那样在范围内全部搜索，而是通过随机选取。思想是如果数据集足够大，那么通过随机采样也能大概率地找到全局最优值或者近似值。

优点：速度快

**缺点：结果不敢保证**



> 网格搜索和随机搜索测试一个新数据的时候，会忽略之前那个点的信息。



##### 贝叶斯优化

通过对目标函数的形状进行学习，找到使目标函数向全局最优解逼近的参数。

**贝叶斯优化会利用之前的样本信息。**

方法：

1. 首先根据先验分布，假设一个搜集函数
2. 每次使用新的样本点来测试目标函数是，利用这个信息更新目标函数的先验分布
3. 算法测试由后验分布给出全局最优解可能出现的位置的点。



注意，如果贝叶斯优化找到一个局部最优解，会在该区域不断采样，所以很容易陷入局部最优解。为了解决这个问题，贝叶斯优化算法会在未取样的区域获取采样点，同时根据后验分布在最可能出现全局最值的区域进行采样。



### 2.7 Overfitting & Underfitting

**Overfitting 过拟合：**因为训练数据的原因，包括sampling、feature等原因，模型对于训练数据拟合过当，导致在训练集中表现很好，但是测试集和新数据上的表现较差。

**Underfitting 欠拟合：**模型在训练和预测时，表现都不好的情况。



#### 2.7.1 降低过拟合风险的方法

1. 增加更多数据，让模型学到更多更有效的特征。
2. 降低模型复杂度，高阶的函数形状更加复杂，采用更简单的模型（奥卡姆剃刀）。
3. 正则化，添加惩罚项penalty，对模型的参数进行约束。
4. 集成学习，如bagging，将多个模型集成在意阿奇，来降低单一模型的过拟合风险。
5. dropout

值得一提的是，bagging和dropout类似。



**正则化为什么可以防止过拟合**

- 令损失函数 L = R(y,f(x)
- 加入一个正则项，也就是惩罚项，通过这个正则项去控制参数W，也就是使W的个数N最小，目标函数从经验风险最小化转换到了结构风险最小化，即L = R(y,f(x)+P(w),然后总的目标是使L最小化
- 引入0，1，2范式，0范式是求非0的个数，1范式是绝对值之和，2范式是模；
- w=0是没有意义的，表示该x没有权重，所以采用0范式，然而0范式是很不好处理的，所以在某些情况下，用1范式代替0范式，0范式和1范式都能实现稀疏。

#### 2.7.2 降低欠拟合风险的方法

1. 添加新特征：当特征不足或者现有特征与样本标签的相关性不强，导致模型出现欠拟合。可以通过挖掘其他新的特征，往往可以取得更好的效果。
2. 增加模型复杂度
3. 减小正则化系数

